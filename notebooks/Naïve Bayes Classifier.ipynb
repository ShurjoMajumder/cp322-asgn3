{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM6jcHJAaVL1kuKDHknDEVs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Na√Øve Bayes Classifier\n","### (a) Loading data and extracting features\n","First, we need to load the data and extract features. We will use CountVectorizer to convert text data into numerical features."],"metadata":{"id":"J8t90mk-mxU2"}},{"cell_type":"code","execution_count":11,"metadata":{"id":"15deoBZTmtYe","executionInfo":{"status":"ok","timestamp":1742409895744,"user_tz":240,"elapsed":54,"user":{"displayName":"ROBIN CHEN","userId":"05460267137544899041"}}},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","\n","def load_data():\n","    real_path = '/fake.txt'\n","    fake_path = '/real.txt'\n","\n","    with open(real_path, 'r', encoding='utf-8') as f:\n","        real_headlines = f.readlines()\n","    with open(fake_path, 'r', encoding='utf-8') as f:\n","        fake_headlines = f.readlines()\n","\n","    headlines = real_headlines + fake_headlines\n","    labels = [1] * len(real_headlines) + [0] * len(fake_headlines)\n","\n","    return headlines, labels\n","\n","\n","\n","def extract_features(headlines):\n","    vectorizer = CountVectorizer()\n","    X = vectorizer.fit_transform(headlines)\n","    return X, vectorizer\n","\n","\n","headlines, labels = load_data()\n","X, vectorizer = extract_features(headlines)\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)"]},{"cell_type":"markdown","source":["### (b) Filtering meaningless words\n","We can filter out words that appear in more than 70% of documents or less than 0.5% of documents by setting the max_df and min_df parameters."],"metadata":{"id":"56ZXSGMHmupC"}},{"cell_type":"code","source":["def filter_words(vectorizer, X):\n","    vectorizer.max_df = 0.7\n","    vectorizer.min_df = 0.005\n","    X_filtered = vectorizer.fit_transform(headlines)\n","    return X_filtered, vectorizer\n","\n","X_filtered, vectorizer = filter_words(vectorizer, X)\n","X_train, X_test, y_train, y_test = train_test_split(X_filtered, labels, test_size=0.3, random_state=42)"],"metadata":{"id":"6lm_OoN0nseQ","executionInfo":{"status":"ok","timestamp":1742409897823,"user_tz":240,"elapsed":59,"user":{"displayName":"ROBIN CHEN","userId":"05460267137544899041"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["### (c) Implementing the Naive Bayes Classifier\n","Next, we implement the Naive Bayes classifier and calculate the accuracy on the test set. We will also generate a confusion matrix."],"metadata":{"id":"nKRylyMhn0HM"}},{"cell_type":"code","source":["from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","import numpy as np\n","\n","\n","def naive_bayes(X_train, X_test, y_train, y_test):\n","\n","    model = MultinomialNB()\n","    model.fit(X_train, y_train)\n","\n","    y_pred = model.predict(X_test)\n","\n","    accuracy = accuracy_score(y_test, y_pred)\n","\n","    cm = confusion_matrix(y_test, y_pred)\n","\n","    return accuracy, cm\n","\n","accuracy, cm = naive_bayes(X_train, X_test, y_train, y_test)\n","print(f\"Test Accuracy: {accuracy}\")\n","print(f\"Confusion Matrix:\\n{cm}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y_32pHMYn0gI","executionInfo":{"status":"ok","timestamp":1742409899083,"user_tz":240,"elapsed":17,"user":{"displayName":"ROBIN CHEN","userId":"05460267137544899041"}},"outputId":"a1272982-987b-4e73-897d-c3c01ae82618"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.8081632653061225\n","Confusion Matrix:\n","[[483  83]\n"," [105 309]]\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"lxCVtgrun7Cc"}}]}