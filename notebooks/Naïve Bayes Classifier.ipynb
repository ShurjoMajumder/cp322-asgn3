{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMOAePxdX2LKoUQu1IyS8Jm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Na√Øve Bayes Classifier\n","### (a) Loading data and extracting features\n","First, we need to load the data and extract features. We will use CountVectorizer to convert text data into numerical features."],"metadata":{"id":"J8t90mk-mxU2"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"15deoBZTmtYe","executionInfo":{"status":"ok","timestamp":1742580821605,"user_tz":240,"elapsed":116,"user":{"displayName":"ROBIN CHEN","userId":"05460267137544899041"}}},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","\n","def load_data():\n","    real_path = '/content/real.txt'\n","    fake_path = '/content/fake.txt'\n","\n","    with open(real_path, 'r', encoding='utf-8') as f:\n","        real_headlines = f.readlines()\n","    with open(fake_path, 'r', encoding='utf-8') as f:\n","        fake_headlines = f.readlines()\n","\n","    headlines = real_headlines + fake_headlines\n","    labels = [1] * len(real_headlines) + [0] * len(fake_headlines)\n","\n","    return headlines, labels\n","\n","\n","\n","def extract_features(headlines):\n","    vectorizer = CountVectorizer()\n","    X = vectorizer.fit_transform(headlines)\n","    return X, vectorizer\n","\n","\n","headlines, labels = load_data()\n","X, vectorizer = extract_features(headlines)\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)"]},{"cell_type":"markdown","source":["### (b) Filtering meaningless words\n","We can filter out words that appear in more than 70% of documents or less than 0.5% of documents by setting the max_df and min_df parameters."],"metadata":{"id":"56ZXSGMHmupC"}},{"cell_type":"code","source":["def filter_words(vectorizer, X):\n","    vectorizer.max_df = 0.7\n","    vectorizer.min_df = 0.005\n","    X_filtered = vectorizer.fit_transform(headlines)\n","    return X_filtered, vectorizer\n","\n","X_filtered, vectorizer = filter_words(vectorizer, X)\n","X_train, X_test, y_train, y_test = train_test_split(X_filtered, labels, test_size=0.3, random_state=42)"],"metadata":{"id":"6lm_OoN0nseQ","executionInfo":{"status":"ok","timestamp":1742580827877,"user_tz":240,"elapsed":39,"user":{"displayName":"ROBIN CHEN","userId":"05460267137544899041"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### (c) Implementing the Naive Bayes Classifier\n","Next, we implement the Naive Bayes classifier and calculate the accuracy on the test set. We will also generate a confusion matrix."],"metadata":{"id":"nKRylyMhn0HM"}},{"cell_type":"code","source":["from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","import numpy as np\n","\n","\n","def naive_bayes(X_train, X_test, y_train, y_test):\n","\n","    model = MultinomialNB()\n","    model.fit(X_train, y_train)\n","\n","    y_pred = model.predict(X_test)\n","\n","    accuracy = accuracy_score(y_test, y_pred)\n","\n","    cm = confusion_matrix(y_test, y_pred)\n","\n","    return accuracy, cm\n","\n","accuracy, cm = naive_bayes(X_train, X_test, y_train, y_test)\n","print(f\"Test Accuracy: {accuracy}\")\n","print(f\"Confusion Matrix:\\n{cm}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y_32pHMYn0gI","executionInfo":{"status":"ok","timestamp":1742580835516,"user_tz":240,"elapsed":31,"user":{"displayName":"ROBIN CHEN","userId":"05460267137544899041"}},"outputId":"71f57660-291b-4405-abe7-663c25c2df7c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.789795918367347\n","Confusion Matrix:\n","[[287  95]\n"," [111 487]]\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"lxCVtgrun7Cc"}}]}